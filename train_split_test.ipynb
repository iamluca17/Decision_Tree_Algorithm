{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\lucab\\AppData\\Local\\Temp\\ipykernel_9188\\4124574360.py:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  banknote_dataset = pd.read_csv(\"resources\\data_banknote_authentication\\data_banknote_authentication.txt\",\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.67650</td>\n",
       "      <td>-5.66360</td>\n",
       "      <td>10.9690</td>\n",
       "      <td>-0.334490</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.82780</td>\n",
       "      <td>7.75980</td>\n",
       "      <td>-2.4491</td>\n",
       "      <td>-1.221600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.81479</td>\n",
       "      <td>-5.73810</td>\n",
       "      <td>4.3919</td>\n",
       "      <td>0.321100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.66620</td>\n",
       "      <td>-0.30005</td>\n",
       "      <td>1.4238</td>\n",
       "      <td>0.024986</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.282300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variance  skewness  curtosis   entropy  type\n",
       "0  -4.67650  -5.66360   10.9690 -0.334490     1\n",
       "1   4.82780   7.75980   -2.4491 -1.221600     0\n",
       "2  -0.81479  -5.73810    4.3919  0.321100     1\n",
       "3  -1.66620  -0.30005    1.4238  0.024986     1\n",
       "4  -3.56370  -8.38270   12.3930 -1.282300     1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['variance', 'skewness', 'curtosis', 'entropy', 'type']\n",
    "banknote_dataset = pd.read_csv(\"resources\\data_banknote_authentication\\data_banknote_authentication.txt\",\n",
    "                               skiprows=1, delimiter=\",\", header=None, names=col_names)\n",
    "\n",
    "banknote_dataset = banknote_dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "banknote_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = banknote_dataset.iloc[:, :-1].values\n",
    "targets = banknote_dataset.iloc[:, -1].values.reshape(-1,1)\n",
    "\n",
    "TRAIN_DATASET_FEATURES, TEST_DATASET_FEATURES, TRAIN_DATASET_OUTCOMES, TEST_DATASET_OUTCOMES = train_test_split(features, targets, test_size=.2,random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'decision_tree' from 'd:\\\\dev\\\\Pred_&_ML_tutorial_model_building\\\\src\\\\decision_tree.py'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import decision_tree as decit\n",
    "\n",
    "importlib.reload(decit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node at depth 0: if x0 <= 0.31803:\n",
      "   Node at depth 1: if x1 <= 5.8333:\n",
      "      Node at depth 2: if x2 <= 4.8486:\n",
      "         Leaf: 1.0\n",
      "      Node at depth 2: else if x2 > 4.8486:\n",
      "         Node at depth 3: if x1 <= -4.5566:\n",
      "            Leaf: 1.0\n",
      "         Node at depth 3: else if x1 > -4.5566:\n",
      "            Leaf: 0.0\n",
      "   Node at depth 1: else if x1 > 5.8333:\n",
      "      Node at depth 2: if x0 <= -4.2249:\n",
      "         Node at depth 3: if x2 <= 1.0836:\n",
      "            Leaf: 1.0\n",
      "         Node at depth 3: else if x2 > 1.0836:\n",
      "            Leaf: 0.0\n",
      "      Node at depth 2: else if x0 > -4.2249:\n",
      "         Leaf: 0.0\n",
      "Node at depth 0: else if x0 > 0.31803:\n",
      "   Node at depth 1: if x0 <= 1.7875:\n",
      "      Node at depth 2: if x2 <= -2.2726:\n",
      "         Node at depth 3: if x1 <= 5.2022:\n",
      "            Leaf: 1.0\n",
      "         Node at depth 3: else if x1 > 5.2022:\n",
      "            Leaf: 0.0\n",
      "      Node at depth 2: else if x2 > -2.2726:\n",
      "         Node at depth 3: if x3 <= 0.087054:\n",
      "            Leaf: 0.0\n",
      "         Node at depth 3: else if x3 > 0.087054:\n",
      "            Leaf: 0.0\n",
      "   Node at depth 1: else if x0 > 1.7875:\n",
      "      Node at depth 2: if x0 <= 2.1943:\n",
      "         Node at depth 3: if x2 <= -2.9581:\n",
      "            Leaf: 1.0\n",
      "         Node at depth 3: else if x2 > -2.9581:\n",
      "            Leaf: 0.0\n",
      "      Node at depth 2: else if x0 > 2.1943:\n",
      "         Leaf: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifier = decit.Decision_Tree_Classifier(min_samples=3, max_depth=3)\n",
    "\n",
    "classifier.fit(TRAIN_DATASET_FEATURES, TRAIN_DATASET_OUTCOMES)\n",
    "classifier.print_tree()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTCOME_PREDICTIONS = classifier.predict_from_dataset(TEST_DATASET_FEATURES)\n",
    "\n",
    "print(np.array )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and unknown targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTEST_DATASET_OUTCOMES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUTCOME_PREDICTIONS\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\dev\\Pred_&_ML_tutorial_model_building\\src\\datasci_tut_venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32md:\\dev\\Pred_&_ML_tutorial_model_building\\src\\datasci_tut_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:227\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m    226\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m attach_unique(y_true, y_pred)\n\u001b[1;32m--> 227\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32md:\\dev\\Pred_&_ML_tutorial_model_building\\src\\datasci_tut_venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:107\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    104\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    109\u001b[0m             type_true, type_pred\n\u001b[0;32m    110\u001b[0m         )\n\u001b[0;32m    111\u001b[0m     )\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    114\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and unknown targets"
     ]
    }
   ],
   "source": [
    "accuracy_score(TEST_DATASET_OUTCOMES, OUTCOME_PREDICTIONS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci_tut_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
